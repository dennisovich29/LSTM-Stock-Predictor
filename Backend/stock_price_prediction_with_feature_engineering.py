# -*- coding: utf-8 -*-
"""Stock Price Prediction with Feature Engineering

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uJx0WfURNVW_cUPYlORVvtoH7sDNAd-1
"""

# Import necessary libraries
import yfinance as yf
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import matplotlib.pyplot as plt

# --- Helper Function for Feature Engineering ---
def create_features(df):
    """Creates time-series features from a stock dataframe."""
    # Simple Moving Averages (SMA)
    df['SMA_20'] = df['Close'].rolling(window=20).mean()
    df['SMA_50'] = df['Close'].rolling(window=50).mean()

    # Exponential Moving Average (EMA)
    df['EMA_20'] = df['Close'].ewm(span=20, adjust=False).mean()

    # Relative Strength Index (RSI)
    delta = df['Close'].diff(1)
    gain = delta.mask(delta < 0, 0)
    loss = -delta.mask(delta > 0, 0)
    avg_gain = gain.ewm(com=13, adjust=False).mean()
    avg_loss = loss.ewm(com=13, adjust=False).mean()
    epsilon = 1e-10
    rs = avg_gain / (avg_loss + epsilon)
    df['RSI'] = 100 - (100 / (1 + rs))

    # Bollinger Bands
    sma_20 = df['Close'].rolling(window=20).mean()
    std_20 = df['Close'].rolling(window=20).std()
    df['BB_Upper'] = sma_20 + (2 * std_20)
    df['BB_Lower'] = sma_20 - (2 * std_20)

    # --- Convert features to percentage difference from Close price ---
    df['SMA_20_pct'] = (df['SMA_20'] - df['Close']) / df['Close']
    df['SMA_50_pct'] = (df['SMA_50'] - df['Close']) / df['Close']
    df['EMA_20_pct'] = (df['EMA_20'] - df['Close']) / df['Close']
    df['BB_Upper_pct'] = (df['BB_Upper'] - df['Close']) / df['Close']
    df['BB_Lower_pct'] = (df['BB_Lower'] - df['Close']) / df['Close']

    # Price Range as a percentage of Close
    df['Price_Range_pct'] = (df['High'] - df['Low']) / df['Close']

    # --- Target Variable: Next Day's Percentage Change ---
    df['Target_Pct_Change'] = df['Close'].pct_change().shift(-1)

    # Drop rows with NaN values
    df.dropna(inplace=True)

    return df

# # --- 1. Data Collection ---
# # Download historical stock data for Apple (AAPL)
# try:
#     aapl_df = yf.download('AAPL', start='2010-01-01', end='2025-06-01')
#     if aapl_df.empty:
#         raise ValueError("No data downloaded. Check the ticker symbol or date range.")
#     print("Successfully downloaded AAPL stock data.")
# except Exception as e:
#     print(f"Error downloading data: {e}")
#     # Fallback to dummy data if download fails
#     date_rng = pd.date_range(start='2010-01-01', end='2025-06-01', freq='B')
#     aapl_df = pd.DataFrame(date_rng, columns=['Date'])
#     aapl_df['Open'] = np.random.uniform(100, 500, size=(len(date_rng)))
#     aapl_df['High'] = aapl_df['Open'] + np.random.uniform(0, 10)
#     aapl_df['Low'] = aapl_df['Open'] - np.random.uniform(0, 10)
#     aapl_df['Close'] = (aapl_df['High'] + aapl_df['Low']) / 2
#     aapl_df['Volume'] = np.random.randint(1000000, 50000000, size=(len(date_rng)))
#     aapl_df.set_index('Date', inplace=True)
#     print("Using dummy data for demonstration.")
# --- 1. Data Collection ---
try:
    aapl_df_raw = yf.download('AAPL', start='2010-01-01', end='2025-06-01')
    if aapl_df_raw.empty:
        raise ValueError("No data downloaded for AAPL.")
    print("Successfully downloaded AAPL stock data.")
except Exception as e:
    print(f"Error downloading data: {e}")

# Flatten and clean data
if isinstance(aapl_df_raw.columns, pd.MultiIndex):
    aapl_df_raw.columns = aapl_df_raw.columns.get_level_values(0)
aapl_df_raw.ffill(inplace=True)

aapl_df_raw

# --- 2. Feature Engineering ---
aapl_df = create_features(aapl_df_raw.copy())

print("\nData after Feature Engineering (showing percentage-based features):")
print(aapl_df[['Close', 'SMA_20_pct', 'RSI', 'Price_Range_pct', 'Target_Pct_Change']].head())

aapl_df.isna().sum()

import seaborn as sns
import matplotlib.pyplot as plt

# Compute the correlation matrix
corr_matrix = aapl_df.corr()

# Plot heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", square=True)
plt.title("Feature Correlation Heatmap")
plt.tight_layout()
plt.show()

aapl_df

# --- 3. Data Preprocessing ---
features = ['SMA_20_pct', 'SMA_50_pct', 'EMA_20_pct', 'RSI', 'BB_Upper_pct', 'BB_Lower_pct', 'Price_Range_pct']
target = 'Target_Pct_Change'
num_features = len(features)

# Combine features and target for scaling
data_to_scale = aapl_df[features + [target]].values

# Scale the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data_to_scale)

# --- 4. Create Training Data ---
look_back = 60
X, y = [], []

for i in range(look_back, len(scaled_data)):
    # X contains the last 'look_back' days of all features
    X.append(scaled_data[i-look_back:i, :-1]) # All columns except the last (target)
    # y contains the scaled target percentage change
    y.append(scaled_data[i, -1]) # The last column

X, y = np.array(X), np.array(y)
X = np.reshape(X, (X.shape[0], X.shape[1], num_features))

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)
# Keep track of the actual close prices for the test set to calculate predicted prices later
actual_close_prices_test = aapl_df['Close'].iloc[-len(X_test):].values

print("\nX_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)

# --- 5. Build the LSTM Model ---
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(look_back, num_features)))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units=1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.summary()

# --- 6. Train the Model ---
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)

# --- 7. Evaluate the Model and Make Predictions ---
# Predict the scaled percentage change
predictions_scaled = model.predict(X_test)

# To inverse transform, we need a dummy array of the correct shape
dummy_array = np.zeros((len(predictions_scaled), num_features + 1))
dummy_array[:, -1] = predictions_scaled.flatten()
predicted_pct_change = scaler.inverse_transform(dummy_array)[:, -1]

# Calculate the predicted stock prices
predicted_prices = []
# The first prediction is based on the day before the test set starts
last_actual_price = aapl_df['Close'].iloc[-len(X_test)-1]

for pct_change in predicted_pct_change:
    predicted_price = last_actual_price * (1 + pct_change)
    predicted_prices.append(predicted_price)
    # For the next prediction, we use the actual price of the current day
    # This prevents compounding errors in the visualization and RMSE calculation.
    # We find the index to get the correct actual price.
    current_index = len(aapl_df) - len(X_test) + len(predicted_prices) - 1
    last_actual_price = aapl_df['Close'].iloc[current_index]

predicted_prices = np.array(predicted_prices)

# Calculate RMSE on the prices
rmse = np.sqrt(np.mean(((predicted_prices - actual_close_prices_test) ** 2)))
print(f"\nRoot Mean Squared Error (RMSE) on AAPL test data: ${rmse:.2f}")

# --- 8. Visualize the Results ---
plot_df = aapl_df.iloc[-len(X_test):].copy()
plot_df['Predictions'] = predicted_prices

plt.figure(figsize=(16, 8))
plt.title('Apple (AAPL) Stock Price Prediction (Based on Pct Change)')
plt.xlabel('Date')
plt.ylabel('Close Price USD ($)')
plt.plot(aapl_df['Close'], label='Actual Price')
plt.plot(plot_df.index, plot_df['Predictions'], label='Predicted Price', alpha=0.7)
plt.legend()
plt.grid(True)
plt.show()

# --- 9. Predict Future Stock Price for AAPL ---
print("\n--- Predicting next day's price for AAPL ---")
# We need the last 'look_back' days of FEATURES from the scaled data.
# The shape should be (60, num_features), which is (60, 7).
# We select all columns except the last one (the target).
last_60_days_features = scaled_data[-look_back:, :-1]

# Reshape this to the format the model expects: (1, timesteps, features)
input_for_prediction = np.reshape(last_60_days_features, (1, look_back, num_features))

# Predict the scaled percentage change
next_day_scaled_pct_change = model.predict(input_for_prediction)

# Inverse transform the prediction
dummy_array_future = np.zeros((1, num_features + 1))
dummy_array_future[0, -1] = next_day_scaled_pct_change[0, 0]
next_day_pct_change = scaler.inverse_transform(dummy_array_future)[0, -1]

# Calculate the predicted price
last_actual_price = aapl_df['Close'].iloc[-1]
predicted_next_day_price = last_actual_price * (1 + next_day_pct_change)

print(f"\nLast actual closing price for AAPL: ${last_actual_price:.2f}")
print(f"Predicted percentage change for next day: {next_day_pct_change:.4%}")
print(f"Predicted closing price for the next trading day: ${predicted_next_day_price:.2f}")

# --- 9. Test Model on New, Unseen Data (e.g., MSFT) ---
print("\n--- Testing model on a different stock (MSFT) without retraining ---")
try:
    # 1. Download and process new data
    new_ticker = 'NVDA'
    new_df_raw = yf.download(new_ticker, start='2010-01-01', end='2025-06-01')
    if isinstance(new_df_raw.columns, pd.MultiIndex):
        new_df_raw.columns = new_df_raw.columns.get_level_values(0)
    new_df_raw.ffill(inplace=True)
    new_df = create_features(new_df_raw.copy())

    # 2. Preprocess using the ORIGINAL scaler
    new_data_to_scale = new_df[features + [target]].values
    new_scaled_data = scaler.transform(new_data_to_scale)

    # 3. Create input sequences
    X_new, y_new_actual_prices = [], []
    for i in range(look_back, len(new_scaled_data)):
        X_new.append(new_scaled_data[i-look_back:i, :-1])
        y_new_actual_prices.append(new_df['Close'].iloc[i])

    X_new = np.array(X_new)
    y_new_actual_prices = np.array(y_new_actual_prices)

    # 4. Make predictions
    new_predictions_scaled = model.predict(X_new)

    # 5. Inverse transform and calculate predicted prices
    dummy_array_new = np.zeros((len(new_predictions_scaled), num_features + 1))
    dummy_array_new[:, -1] = new_predictions_scaled.flatten()
    new_predicted_pct_change = scaler.inverse_transform(dummy_array_new)[:, -1]

    new_predicted_prices = []
    last_actual_price_new = new_df['Close'].iloc[look_back-1]
    for i in range(len(new_predicted_pct_change)):
        price = new_df['Close'].iloc[look_back + i -1] * (1 + new_predicted_pct_change[i])
        new_predicted_prices.append(price)

    new_predicted_prices = np.array(new_predicted_prices)

    # 6. Visualize and evaluate
    new_rmse = np.sqrt(np.mean(((new_predicted_prices - y_new_actual_prices) ** 2)))
    print(f"\nRoot Mean Squared Error (RMSE) on {new_ticker} data: ${new_rmse:.2f}")

    plt.figure(figsize=(16, 8))
    plt.title(f'{new_ticker} Stock Price Prediction using Generalized Model')
    plt.xlabel('Date')
    plt.ylabel('Close Price USD ($)')
    plt.plot(new_df.index, new_df['Close'], label='Actual Price')
    plt.plot(new_df.index[look_back:], new_predicted_prices, label='Predicted Price', alpha=0.7)
    plt.legend()
    plt.grid(True)
    plt.show()

except Exception as e:
    print(f"An error occurred while testing on new data: {e}")

